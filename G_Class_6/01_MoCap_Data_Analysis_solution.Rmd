---
date: "2023-11-06"
title: "Class G, Mocap data"
author: "Luke Ring / zeyus"
output: html_document
---

# Normal setup stuff

You will have to change a few things here...

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# to make things easy, we will use pacman. Please install it if you don't have it already
# with install.packages("pacman")

# packages to load
pacman::p_load(
  "XML",
  "tidyverse",
  "fs",
  "assertthat",
  "stringi",
  "dtw",
  "RTransferEntropy",
  "signal",
  "conflicted",
  "Rcpp",
  "future"
)

# make sure we are in the G_Class_6 directory
wd <- getwd()
if (basename(wd) != "G_Class_6") {
  setwd("./G_Class_6")
}

# set the directory for the data
# note, path_home() will return the path to your home directory
# your home directory is the one that contains your documents, downloads, etc.
data_dir <- path_home() %>% 
  path("OneDrive - Aarhus universitet", "PercActMotionCapture", "labeled_data", "tsvs")

# set your study group
group_number <- 0

# The available conditions and their start and end frame indices
# to use the whole file, just set the value for the condition to c(NA, NA)
conditions <- list(
  jointlead = c(NA, NA),
  followlead = c(NA, NA),
  leadfollow = c(NA, NA),
  custom = c(NA, NA)
)



```

# Defining some helper functions

**Note:** These functions have been moved to `mocap_utils.R`.

These you don't need to worry too much about, this is mainly the boring data collation stuff.

I have defined a `gap_fill_linear` function that is a useful concept to understand at least.
With mocap trajectories, often some data might be missing due to markers being occluded etc.
When this happens, we need to either discard those segments (or pick segments with full coverage),
or alternatively, we can gap fill the missing data. This implementation is the most basic possible gap
filling, it essentially draws a straight line between the two points either side of the missing data.


And so, some more boring stuff...
This is just getting the labels so we can make sure that the tracked markes match up with what we expected,
really, this shouldn't go wrong, but if you don't check this kind of thing you'll end up scratching your head
later wondering why everything broke.

```{r 'Load Trajectory Labels'}
# load the labels from the XML file
read_trajectory_labels("./resources/PerAct23_LabelList.xml")

```

# Load in the data

Here is where we get the files that are of interest...Start with the ones from your group,
if you're extra super keen, then you can also try broader analyses across groups.

```{r 'Load Trajectory Data'}

# load the trajectory data, we want all TSVs with the group number in the name

# get the files
traj_files <- fs::dir_ls(data_dir, regexp = paste0("group", group_number, "_.*\\.tsv$"))

# load the data
traj_data <- lapply(traj_files, process_qtm_tsv)

# now we need to combine the data into a single data frame

# first we need to add the condition and group to each data frame
traj_data <- lapply(traj_data, function(x) {
  x$data$condition <- x$metadata$condition
  x$data$group <- paste0("group", group_number)
  return(x)
})

# now we can combine the data
traj_data <- do.call(bind_rows, lapply(traj_data, `[[`, "data"))

# make the condition and group factors
traj_data$condition <- factor(traj_data$condition)
traj_data$group <- factor(traj_data$group)

# take a look at the data
head(traj_data)

# let's also make sure that all of the marker names are the same
# we can do this by getting the unique marker names
marker_names <- unique(traj_data %>% select(contains("_x")) %>% names() %>% stri_replace_last_regex("_x", ""))

# now we can check that all of the marker names are the same
assertthat::assert_that(
  all(marker_names == traj_labels$traj_names),
  msg = "Not all marker names are the same"
)

# let's make the data long format so we can easily group by subject or marker
traj_data <- traj_data %>% 
  pivot_longer(
    cols = contains("_x") | contains("_y") | contains("_z"),
    cols_vary = "slowest",
    names_to = "marker",
    values_to = "value"
  ) %>%
  mutate(
    subject = stri_replace_first_regex(marker, "^([AB])_.*", "$1"),
    axis = stri_extract_last_regex(marker, "[xyz]$"),
    marker = stri_replace_first_regex(marker, "^[AB]_([a-zA-Z_]+)_[xyz]$", "$1")
  )
traj_data
# move axes to columns
traj_data <- traj_data %>% 
  pivot_wider(
    names_from = axis,
    values_from = value
  )
traj_data$marker <- factor(traj_data$marker)
```

# Trim the trajectories

Here's where you cut the start and ends off of the trajectores, this is useful for example
when you know that there's some setup time or a delay from recording start to end, or if you just 
want to look at a specific section of the data.

If you set up the conditions correctly in the setup section, then you can just run this cell and it will
crop the data for you.

```{r 'Crop trajectory data'}

# We want to crop the data for each condition
# let's get all the recorded conditions
recorded_conditions <- unique(traj_data$condition)
for (cond in recorded_conditions) {
  # get the start and end frame for the condition
  start_frame <- conditions[[cond]][1]
  if (is.na(start_frame)) start_frame <- 1
  end_frame <- conditions[[cond]][2]
  if (is.na(end_frame)) end_frame <- max(traj_data[traj_data$condition == cond, "index"])
  # crop the data
  traj_data <- traj_data %>% 
    dplyr::filter(condition == cond & index >= start_frame & index <= end_frame | condition != cond)
}

# select min and max indices by condition
traj_data %>% 
  group_by(condition) %>% 
  summarise(
    min_index = min(index),
    max_index = max(index))

# report observations per condition
traj_data %>% 
  group_by(condition, subject, marker) %>% 
  summarise(
    n_obs = n()
  ) %>%
  print(n = 100)

```

# Inspect the data

I've included some ways here of inspecting the data to see if there are any obvious problems.

## Check for large jumps in trajectory data

This is a simple check to see if there are any large jumps in the data, this can indicate that there are
some label errors (e.g. label `hand_left` became label `hand_right`), or that the data is just bad.

```{r 'Check for large jumps in trajectory data'}
# we want to check for large jumps in the data
# this indicates potential label errors

# we will do this by calculating the distance between each marker for each time point
# of course, by condition



# calculate the euclidean distance between each marker (using x, y, z)
# we will do this by condition, subject, marker and axis
marker_distances <- traj_data %>% 
  group_by(condition, subject, marker) %>%
  arrange(index) %>%
  mutate(
    diff_x = x - dplyr::lag(x, 1),
    diff_y = y - dplyr::lag(y, 1),
    diff_z = z - dplyr::lag(z, 1)
  )

# now we can calculate the euclidean distance per maker
marker_distances <- marker_distances %>% 
  mutate(
    euclidean_distance = sqrt(diff_x^2 + diff_y^2 + diff_z^2)
  )

# now we can plot the series for each marker, and see if anything stands out
marker_distances %>% 
  ggplot(aes(x = index, y = euclidean_distance, color = marker)) +
  geom_line(linewidth=1.25) +
  theme_minimal() +
  facet_wrap(c(~condition, ~subject)) +
  labs(
    x = "Index",
    y = "Euclidean distance",
    title = "Euclidean distance from previous frame by marker"
  )
marker_distances
# save the plot
ggsave(
  filename = "./results/euclidean_distance_by_marker.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

```

# Check for NAs

Specifically, this checks how much of a given trajectory is `NA` values and how long the longest sequence
of `NA` values is. This can be useful for deciding whether to discard a marker or not.

*Remember, you'll want to make sure that both subject A and B have at least one good quality matching marker.*

```{r 'Get information about NAs'}	

# get NAs counts
# by condition, marker, subject and axis
nas_cond_marker <- traj_data %>%
  group_by(condition, subject, marker) %>%
  summarise_at(
    vars(x, y, z),
    ~ sum(is.na(.))
  )


# plot to check if it is acceptable
nas_cond_marker %>% 
  ggplot(aes(x = marker, y = x, fill=marker, group=subject)) +
  geom_col(
    show.legend = FALSE
  ) +
  coord_flip() +
  theme_minimal() +
  facet_wrap(c(~subject, ~condition)) +
  labs(
    x = "Marker",
    y = "NA count",
    title = "NA count by marker"
  )

ggsave(
  filename = "./results/NA_count_by_marker.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)


# Now we can get the longest sequence of NAs for each marker
longest_na_seq <- traj_data %>% 
  group_by(condition, subject, marker) %>%
  summarise_at(
    vars(x, y, z),
    ~ max(rle(is.na(.))$lengths)
  )

# plot to check if it is acceptable
longest_na_seq %>% 
  ggplot(aes(x = marker, y = x, fill=marker, group=subject)) +
  geom_col(
    show.legend = FALSE
  ) +
  coord_flip() +
  theme_minimal() +
  facet_wrap(c(~subject, ~condition)) +
  labs(
    x = "Marker",
    y = "Longest NA sequence",
    title = "Longest NA sequence by marker"
  )

ggsave(
  filename = "./results/longest_na_sequence_by_marker.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

```

# Pick your poison

You can choose one or more markers and put them in the `markers_of_interest` variable below. This will
then be used for the rest of the analysis.

```{r 'Choose markers of interest'}
# we want to choose the markers of interest
# we will choose the following markers:
# - {A,B}_head_top
# - {A,B}_hand_right
# you may of course choose different markers, or if those ones were
# particularly bad, you should select others

# get the markers of interest
markers_of_interest <- c(
  "hand_right"
)

# now we can select the markers of interest
selected_traj_data <- traj_data %>% 
  dplyr::filter(marker %in% markers_of_interest)

```

# Gap filling

Now that we're left with mainly the data we want to work with, we can do some gap filling to eliminate
any `NA` values, just beware that it can't fill NAs at the start or end of the data.

```{r 'Gap fill trajectory data'}
# we are only going to do a linear gap fill, it's not elegant, but it works
# we will do this for each marker x, y, and z

# choose a single marker from markers_of_interest for plotting purposes only
sel_idx <- 1
 
# plot a single marker's x, y, and z values before and after gap filling
selected_traj_data %>%
  dplyr::filter(marker == markers_of_interest[sel_idx]) %>%
  ggplot(aes(x = elapsed_time, y = x, color = subject)) +
  geom_line() +
  theme_minimal() +
  facet_wrap(c(~condition)) +
  labs(
    x = "Elapsed time",
    y = "Marker X position",
    title = paste("Marker", markers_of_interest[sel_idx], "X position before gap filling")
  )

ggsave(
  filename = paste0(
    "./results/marker_",
    markers_of_interest[sel_idx],
    "_x_position_before_gap_filling.png"),
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

# now we can apply our linear gap fill function to each column, by condition
selected_traj_data <- selected_traj_data %>% 
  group_by(condition, subject, marker) %>% 
  mutate_at(
    vars(x, y, z),
    ~ gap_fill_linear(.)
  )

# plot a single marker's x, y, and z after gap filling
selected_traj_data %>%
  dplyr::filter(marker == markers_of_interest[sel_idx]) %>%
  ggplot(aes(x = elapsed_time, y = x, color = subject)) +
  geom_line() +
  theme_minimal() +
  facet_wrap(c(~condition)) +
  labs(
    x = "Elapsed time",
    y = "Marker X position",
    title = paste("Marker", markers_of_interest[sel_idx], "X position after gap filling")
  )

ggsave(
  filename = paste0(
    "./results/marker_",
    markers_of_interest[sel_idx],
    "_x_position_after_gap_filling.png"),
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

```

# ANALYSIS TIME ðŸ¥³

Let's get to it. This is a Cross correlation analysis. This works by correlating the time series of one marker
for subject A with the time series of the same marker for subject B. This can be useful for seeing if there is
any lag between the two subjects, or if there is any correlation between the two subjects.

What do you think lag means? What does correlated in this context mean?

Try and think about this in the context of movement, and then include the fact that the data is represented
as numbers along an axis, will this affect anything?

`ccf` is a function from the `stats` package, you can read more about it here:
https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/acf

```{r 'Cross correlation analysis'}
# we want to do a cross correlation analysis
# we know there are always two subjects, and the
# marker labels start with the subject (A or B)
# we want to cross correlate between the same marker for
# subject A and subject B

# set the maximum lag in samples. e.g. 300 samples is 1 second
max_lag <- 900 # correlate with +/- 3 seconds

# define an empty list to store the results
xcor_results <- list()
for (marker in markers_of_interest) {
  # get the data for the marker
  marker_data <- selected_traj_data %>% 
    dplyr::filter(marker == marker)
  # get the unique conditions
  conds <- unique(marker_data$condition)
  # now we can do the cross correlation analysis
  for (cond in conds) {
    # get the data for the condition
    cond_data <- marker_data %>% 
      dplyr::filter(condition == cond)
    # now we can do the cross correlation analysis
    # we will do this for each axis
    for (axis in c("x", "y", "z")) {
      # this is the function that runs the cross correlation
      # time series one goes in x
      # time series two goes in y
      results <- ccf(
        x = cond_data[cond_data$subject == "A", axis],
        y = cond_data[cond_data$subject == "B", axis],
        na.action = na.omit,
        plot = FALSE,
        lag.max = max_lag
      )
      # make a tibble with the results
      results <- tibble(
        lagv = results$lag,
        acfv = results$acf,
        marker = marker,
        condition = cond,
        axis = axis
      )
      xcor_results[[length(xcor_results) + 1]] <- results
    }
  }
}

# let's put all the acf results into a single tibble
xcor_results <- do.call(bind_rows, xcor_results)


# now we can plot the results for each lag point
xcor_results %>%
  ggplot(aes(x = lagv, y = acfv, color = axis)) +
  geom_point() +
  theme_minimal() +
  facet_wrap(c(~condition, ~marker)) +
  labs(
    x = "Lag",
    y = "Autocorrelation",
    title = "Autocorrelation by lag"
  )

# save the plot
ggsave(
  filename = "./results/autocorrelation_by_lag.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

# let's also get the min and max autocorrelation for each condition and marker
xcor_results %>%
  group_by(condition, marker, axis) %>%
  summarise(
    min = min(acfv),
    max = max(acfv),
    lag_min = lagv[which.min(acfv)],
    lag_max = lagv[which.max(acfv)]
  )

```

# Windowed cross correlation analysis

This is the same as above, but we will do it in windows. This can be useful for seeing if there are any
changes in the correlation over time.

How does this relate to synchrony?

Have a play around with the parameters below, see what happens.

Again this uses the `ccf` function from `stats`, but the windowing is implemented manually here,
there are packages you can get that automate the windowing of data in R, e.g. `zoo`.
https://cran.r-project.org/web/packages/zoo/index.html

```{r 'Windowed cross correlation analysis'}
# windowed version of the cross correlation analysis

# Mess around with the values below, see what happens! :)

# set the window size in samples
window_size <- 600 # 2 seconds
max_lag <- 150 # 0.5 seconds
step_size <- 300 # 1 second
axes_of_interest = c("x", "y")

# define an empty list to store the results
xcor_results <- list()
conds <- unique(selected_traj_data$condition)
for (marker in markers_of_interest) {
  # loop conditions
  for (cond in conds) {
    # get the data for the condition
    cond_data <- selected_traj_data %>% 
      dplyr::filter(
        marker == marker &
        condition == cond)
    # loop axes
    for (axis in axes_of_interest) {
      # get the data for the axis
      axis_data <- cond_data %>% 
        ungroup() %>%
        dplyr::select(subject, axis)
      subjA <- axis_data[axis_data$subject == "A", axis]
      subjB <- axis_data[axis_data$subject == "B", axis]
      row_count <- nrow(subjA)
      # we will do this for each window
      for (window_start in seq(1, row_count - window_size, step_size)) {
        # get the window end
        window_end <- window_start + window_size - 1
        # make sure we don't go over the end of the data
        if (window_end > row_count) {
          window_end <- row_count
        }
        # now we can do the cross correlation analysis
        results <- NULL
        tryCatch({
          # this is the function that runs the cross correlation
          # time series one goes in x
          # time series two goes in y
          results <- ccf(
            x = subjA[window_start:window_end,],
            y = subjB[window_start:window_end,],
            na.action = na.omit,
            plot = FALSE,
            lag.max = max_lag
          )
          # make a tibble with the results
          results <- tibble(
            lagv = results$lag,
            acfv = results$acf,
            marker = marker,
            condition = cond,
            axis = axis,
            window_start = window_start,
            window_end = window_end
          )
          xcor_results[[length(xcor_results) + 1]] <- results
        },
        error = function(e) {
          warning(paste(
            "Error doing cross correlation analysis, too many NAs?",
            "Condition:",
            cond,
            "Marker:",
            marker,
            "Axis:",
            axis,
            "Window start:",
            window_start,
            "Window end:",
            window_end,
            "Error:",
            e
            )
          )
          results <- NULL
        }
        )
      }
    }
  }
}

xcor_results <- do.call(bind_rows, xcor_results)

# plot a heatmap for each condition, marker, axis
xcor_results %>%
  ggplot(aes(x = lagv, y = window_start, fill = acfv)) +
  geom_tile() +
  scale_fill_distiller(palette = "Spectral") +
  theme_minimal() +
  facet_wrap(c(~condition, ~marker, ~axis)) +
  labs(
    x = "Lag",
    y = "Window start",
    title = "Autocorrelation by lag and window start"
  )

# save the plot
ggsave(
  filename = "./results/autocorrelation_by_lag_and_window_start.png",
  width = 10,
  height = 10,
  units = "cm",
  dpi = 300
)

```

# Dynamic time warping

This is a way of comparing two time series that is used in speech recognition,
music information retrieval, neuroscience, and many other fields.

Try messing around with the decimate_factor, window size, etc.

The main function that runs the dynamic time warping is `dtw` from the `dtw` package.
You can find more information here https://dtw.r-forge.r-project.org/

```{r 'Dynamic time warping for a single marker'}
# we want to do dynamic time warping for a single marker
# we will do this for each condition
# To do this, it's just a matter of getting the time series for each subject and condition

# pick a single marker to do the analysis on
sel_marker <- markers_of_interest[1]
conds <- unique(selected_traj_data$condition)
# define the window size (in samples)
# this is how far ahead and behind we can look for a match
# you can play around with these values, but keep in mind
# DTW is very processor heavy and can take some time

axes_of_interest <- c("x", "y")
original_sample_rate <- 300

decimate_factor <- 6 # meaning our new sample rate is 50 Hz
window_size_samples <- 50 # meaning our window size is 1 second

# this is a disgusting resampling method
resampled_traj_data <- selected_traj_data %>%
  group_by(condition, subject, marker) %>%
  dplyr::filter(
    index %% decimate_factor == 0
  ) %>%
  ungroup()

# finally, we may benefit from standardizing the data
# if we do this by condition, subject and marker
# we can compare relative movements between subjects
# for specific markers, but we loose the distance between them
# if we use condition and subject, we keep the relative marker distance
# within a subject, but we loose the relative distance between subjects
resampled_traj_data <- resampled_traj_data %>% 
  group_by(condition, subject, marker) %>%
  mutate_at(
    vars(x, y, z),
    ~ scale(.)
  ) %>%
  ungroup()

results <- list()
for (cond in conds) {
  for (axis in axes_of_interest) {
    # get the data for the condition
    cond_data <- resampled_traj_data %>% 
      dplyr::filter(condition == cond & marker == sel_marker)
    # now we can do the dynamic time warping for the marker between subjects
    message(paste("
      Doing dynamic time warping for condition:",
      cond,
      "Marker:",
      sel_marker,
      "Axis:",
      axis))
    message("This may take a while...")
    result <- NULL
    tryCatch({
      # Do the actual DTW analysis
      # x is the time series for subject A
      # y is the time series for subject B
      # the window type is sakoechiba, which is a type of window that
      # constrains the warping path to a band (+/- window.size)
      result <- dtw(
          x = cond_data[cond_data$subject == "A", axis],
          y = cond_data[cond_data$subject == "B", axis],
          window.type = "sakoechiba",
          window.size = window_size_samples,
          keep = TRUE
        )
      },
      error = function(e) {
        warning(paste(
          "Error doing DTW, skipping...maybe try standardizing?",
          "Condition:",
          cond,
          "Marker:",
          sel_marker,
          "Axis:",
          axis,
          "Length of A:",
          length(cond_data[cond_data$subject == "A", axis]),
          "Length of B:",
          length(cond_data[cond_data$subject == "B", axis]),
          "Error:",
          e
          )
        )
        result <- NULL
      }
    )
    if (is.null(result)) {
      message("Skipping...check warning messages at end of output")
      next
    }
    results[[length(results) + 1]] <- list(
      condition = cond,
      marker = sel_marker,
      axis = axis,
      normalizedDistance = result$normalizedDistance,
      distance = result$distance
    )
      

    # plot the results
    message("Plotting results...")
    message("Generating alignment plot...")
    png(
      paste0(
        "./results/DTW_alignment_plot_",
        cond,
        "_",
        sel_marker,
        "_",
        axis,
        ".png"
      )
    )
    plot(result, type = "alignment")
    dev.off()

    message("Generating twoway plot...")
    png(
      paste0(
        "./results/DTW_twoway_plot_",
        cond,
        "_",
        sel_marker,
        "_",
        axis,
        ".png"
      )
    )
    plot(result, type = "twoway")
    dev.off()
    
    message("Generating threeway plot...")
    plot(result, type = "threeway")

    dev.off()
    message("Generating density plot, burning computer...")
    png(
      paste0(
        "./results/DTW_density_plot_",
        cond,
        "_",
        sel_marker,
        "_",
        axis,
        ".png"
      )
    )
    plot(result, type = "density")
    dev.off()
    # save the density plot

  }
}


# print the resulting normalized distances
results

```

# Transfer entropy analysis

This is a way of measuring the transfer of information between two time series. In the context 
of the movement of two subjects, this can be useful for seeing if one subject is leading the other, for example.

Can you think of any other ways this might be useful?

There are various R packages for doing transfer entropy analysis, in this case we use the `RTransferEntropy` package.
https://cran.r-project.org/web/packages/RTransferEntropy/vignettes/transfer-entropy.html


```{r 'Transfer entropy analysis'}
# we want to do a transfer entropy analysis
sel_marker <- markers_of_interest[1]
conds <- unique(selected_traj_data$condition)
axes_of_interest = c("x", "y", "z")



results <- list()
plan(multisession)
for (cond in conds) {
  for (axis in axes_of_interest) {
    # get the data for the condition
    cond_data <- selected_traj_data %>% 
      dplyr::filter(condition == cond & marker == sel_marker)
    # now we can do the transfer entropy analysis for the marker between subjects
    message(paste("
      Doing transfer entropy analysis for condition:",
      cond,
      "Marker:",
      sel_marker,
      "Axis:",
      axis))
    message("This may take a while...")
    result <- NULL
    tryCatch({
        result <- transfer_entropy(
          x = cond_data[cond_data$subject == "A", axis],
          y = cond_data[cond_data$subject == "B", axis]
        )
      },
      error = function(e) {
        warning(paste(
          "Error doing transfer entropy analysis, skipping...maybe try standardizing?",
          "Condition:",
          cond,
          "Marker:",
          sel_marker,
          "Axis:",
          axis,
          "Length of A:",
          length(cond_data[cond_data$subject == "A", axis]),
          "Length of B:",
          length(cond_data[cond_data$subject == "B", axis]),
          "Error:",
          e
          )
        )
        result <- NULL
      }
    )
    if (is.null(result)) {
      message("Skipping...check warning messages at end of output")
      next
    }
    results[[length(results) + 1]] <- list(
      condition = cond,
      marker = sel_marker,
      axis = axis,
      te = result
    )
  }
}
plan(sequential)
# print the resulting transfer entropy values
results

```


# What's next?

You can try different markers, groups, etc. You can also think of ways to use the numbers you get out of the analysis
to make some kind of statement about the movement of the subjects.

How might you go about doing this across multiple trials, subjects, etc.?

<3
